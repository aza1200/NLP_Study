{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class 모델 이용해서 구현\n",
    "\n",
    "sentences = \"\"\"We are about to study the idea of a computational process.\n",
    "Computational processes are abstract beings that inhabit computers.\n",
    "As they evolve, processes manipulate other abstract things called data.\n",
    "The evolution of a process is directed by a pattern of rules\n",
    "called a program. People create programs to direct processes. In effect,\n",
    "we conjure the spirits of the computer with our spells.\"\"\"\n",
    "\n",
    "import re\n",
    "\n",
    "# remove special characters and replace with ' '\n",
    "# [] => 나열된 문자 혹은 범위에 해당하는 문자\n",
    "\n",
    "# 특수문자 제거\n",
    "sentences = re.sub('[^A-Za-z0-9]+', ' ', sentences)\n",
    "\n",
    "# remove 1 letter word 첫부분 한단어,끝부분 한단어, 중간 한단어짜리 지움\n",
    "# ?: non-capturing group -> 대충 매칭되도 무시하겠다 이런뜻\n",
    "sentences =  re.sub(r'(?:^| )\\w(?:$| )', ' ', sentences).strip()\n",
    "\n",
    "# lower all characters\n",
    "sentences = sentences.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226\n"
     ]
    }
   ],
   "source": [
    "words = sentences.split()\n",
    "vocab = set(words)\n",
    "vocab_size = len(vocab)\n",
    "embed_dim = 10\n",
    "\n",
    "# sliding window 의 한쪽 면이라고 생각하는게 편한거 같다. \n",
    "context_size = 2\n",
    "\n",
    "# implementation\n",
    "word_to_idx = {word: i for i,word in enumerate(vocab)}\n",
    "idx_to_word = {i:word for i,word in enumerate(vocab)}\n",
    "\n",
    "data = []\n",
    "for center_word_pos in range(len(words)):\n",
    "    center_word_idx = word_to_idx[words[center_word_pos]]\n",
    "    for w in range(-context_size, context_size+1):\n",
    "        context_word_pos = center_word_pos + w\n",
    "        if context_word_pos < 0 or context_word_pos >= len(words) or center_word_pos == context_word_pos:\n",
    "            continue\n",
    "        context_word_idx = word_to_idx[words[context_word_pos]]\n",
    "        data.append((center_word_idx, context_word_idx))\n",
    "print(len(data))\n",
    "# 변수 정리 \n",
    "# vocab (43개 set) : 문장 단어set 변환\n",
    "# context_size : window 크기\n",
    "# word_to_idx : 단어보고 숫자 변환\n",
    "# idx_to_word : 숫자보고 단어 변환\n",
    "# data : [훈련시킬 데이터, 정답라벨] 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 0 : 3.862834119163783\n",
      "Loss at epoch 10 : 2.171995179315584\n",
      "Loss at epoch 20 : 2.0106027065652663\n",
      "Loss at epoch 30 : 1.9727767426355751\n",
      "Loss at epoch 40 : 1.9562668863650972\n",
      "Loss at epoch 50 : 1.9466003981311764\n",
      "Loss at epoch 60 : 1.9399442501300204\n",
      "Loss at epoch 70 : 1.9348694716407135\n",
      "Loss at epoch 80 : 1.931030275547399\n",
      "Loss at epoch 90 : 1.9291293549854143\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the model\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        \n",
    "        # input dimension 은 2차원이 되어야함\n",
    "        self.layer_1 = nn.Linear(43, 10)\n",
    "        self.layer_2 = nn.Linear(10, 43)\n",
    "    def forward(self, x):\n",
    "        x = self.layer_1(x)\n",
    "        x = self.layer_2(x)\n",
    "        return x\n",
    "\n",
    "model = MyModel()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loss_val = 0\n",
    "    for context, target in data:\n",
    "        \n",
    "        input_one_hot = torch.zeros(len(word_to_idx))\n",
    "        input_one_hot[context] = 1\n",
    "        input_one_hot.unsqueeze_(0)\n",
    "\n",
    "        # label 차원은 (1,1) 이 아닌 (1, ) 이 되어야한다.\n",
    "        # (1,) =>\n",
    "        label = torch.Tensor([target]).long()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_one_hot)\n",
    "        loss = criterion(outputs,label)\n",
    "        loss_val += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Loss at epoch {epoch} : {loss_val/len(data)}')   \n",
    "\n",
    "# 정확도 측정은 어떻게 하지?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
