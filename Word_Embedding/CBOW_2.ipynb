{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CBOW_1을 pytorch 그리고 첫쨰 결과값 pytorch 로 순수 미분으로 구하는것 코드 \n",
    "\n",
    "# 솔직히 CBOW_1 제대로 이해 안됨\n",
    "# 1. 평균을 안하고 걍 이어붙임\n",
    "# 2. 역전파를  맨 끝에만 해서 계산함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentences = \"\"\"We are about to study the idea of a computational process.\n",
    "Computational processes are abstract beings that inhabit computers.\n",
    "As they evolve, processes manipulate other abstract things called data.\n",
    "The evolution of a process is directed by a pattern of rules\n",
    "called a program. People create programs to direct processes. In effect,\n",
    "we conjure the spirits of the computer with our spells.\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# remove special characters and replace with ' '\n",
    "# [] => 나열된 문자 혹은 범위에 해당하는 문자\n",
    "\n",
    "# 특수문자 제거\n",
    "sentences = re.sub('[^A-Za-z0-9]+', ' ', sentences)\n",
    "\n",
    "# remove 1 letter word 첫부분 한단어,끝부분 한단어, 중간 한단어짜리 지움\n",
    "# ?: non-capturing group -> 대충 매칭되도 무시하겠다 이런뜻\n",
    "sentences =  re.sub(r'(?:^| )\\w(?:$| )', ' ', sentences).strip()\n",
    "\n",
    "# lower all characters\n",
    "sentences = sentences.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = sentences.split()\n",
    "vocab = set(words)\n",
    "vocab_size = len(vocab)\n",
    "embed_dim = 10\n",
    "\n",
    "# sliding window 의 한쪽 면이라고 생각하는게 편한거 같다. \n",
    "context_size = 2\n",
    "\n",
    "# implementation\n",
    "word_to_idx = {word: i for i,word in enumerate(vocab)}\n",
    "idx_to_word = {i:word for i,word in enumerate(vocab)}\n",
    "\n",
    "\n",
    "# 변수 정리 \n",
    "# vocab (43개 set) : 문장 단어set 변환\n",
    "# context_size : window 크기\n",
    "# word_to_idx : 단어보고 숫자 변환\n",
    "# idx_to_word : 숫자보고 단어 변환\n",
    "# data : [훈련시킬 데이터, 정답라벨] 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0, loss : 4.384628 accuracy: 0.0%\n",
      "epoch : 10, loss : 3.457874 accuracy: 59.26%\n",
      "epoch : 20, loss : 0.796906 accuracy: 98.15%\n",
      "epoch : 30, loss : 0.147473 accuracy: 100.0%\n",
      "epoch : 40, loss : 0.057648 accuracy: 100.0%\n",
      "epoch : 50, loss : 0.028062 accuracy: 100.0%\n",
      "epoch : 60, loss : 0.01623 accuracy: 100.0%\n",
      "epoch : 70, loss : 0.009981 accuracy: 100.0%\n",
      "epoch : 80, loss : 0.006415 accuracy: 100.0%\n",
      "epoch : 90, loss : 0.004339 accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "#print(sentences)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "data = []\n",
    "for i in range(2, len(words)-2):\n",
    "    context = [words[i-2], words[i-1], words[i+1], words[i+2]]\n",
    "    target = words[i]\n",
    "    data.append((context, target))\n",
    "\n",
    "# Define the model\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.layer_1 = nn.Linear(43, 10)\n",
    "        self.layer_2 = nn.Linear(10, 43)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, *xs):\n",
    "        x = sum(self.layer_1(xi) for xi in xs) / len(xs)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer_2(x)\n",
    "        return x\n",
    "    \n",
    "model = MyModel()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 100\n",
    "batch_size = 43\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    num_correct = 0\n",
    "    num_total = 0\n",
    "    for context, target in data:\n",
    "        inputs = torch.Tensor([word_to_idx[w] for w in context]).long()\n",
    "        \n",
    "        inputs_one_hot = torch.zeros(4,len(word_to_idx))\n",
    "        inputs_one_hot.scatter_(1,inputs.unsqueeze(1),1)\n",
    "        inputs_one_hot.unsqueeze_(1)\n",
    "\n",
    "        labels = torch.Tensor([word_to_idx[target]]).long()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(*inputs_one_hot)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        num_correct += (predicted == labels).sum().item()\n",
    "        num_total += 1\n",
    "    if epoch % 10 == 0:\n",
    "        accuracy = round((num_correct / num_total) * 100,2)\n",
    "        print(f\"epoch : {epoch}, loss : {round(float(loss),6)} accuracy: {accuracy}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
